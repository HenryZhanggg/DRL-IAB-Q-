{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a44020e-a8c9-47d5-b77b-e20dd96e4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac89ca69-7307-4180-888b-b470de1ceb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.cuda.device_count()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be980832-fda5-450b-b934-b87954cafd34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install datasets rouge_score torchmetrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b53dc897-d035-489c-8a15-676b235ef123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForLanguageModeling, Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "086f4e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MedicalDialogueDataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        # 加载数据集\n",
    "        ds = load_dataset(\"omi-health/medical-dialogue-to-soap-summary\", split=split)\n",
    "        \n",
    "        # 移除不需要的列\n",
    "        columns_to_remove = ['messages', 'prompt']\n",
    "        ds = ds.remove_columns(columns_to_remove)\n",
    "        \n",
    "        # 替换换行符并重命名列\n",
    "        # ds = ds.map(self.replace_newline_with_space)\n",
    "        ds = ds.rename_column('soap', 'summary')\n",
    "        \n",
    "        # 添加ID和格式化摘要\n",
    "        ds = ds.map(self.add_id, with_indices=True)\n",
    "        ds = ds.map(self.format_summary)\n",
    "        \n",
    "        self.data = ds\n",
    "\n",
    "    # def replace_newline_with_space(self, example):\n",
    "        # example['dialogue'] = example['dialogue'].replace('\\n', ' ')\n",
    "        # return example\n",
    "    \n",
    "    def add_id(self, example, idx):\n",
    "        example['id'] = str(idx)\n",
    "        return example\n",
    "    \n",
    "    def format_summary(self, example):\n",
    "        example['summary'] = example['summary'].replace('S: ', 'Subjective: ')\n",
    "        example['summary'] = example['summary'].replace('O: ', 'Objective: ')\n",
    "        example['summary'] = example['summary'].replace('A: ', 'Assessment: ')\n",
    "        example['summary'] = example['summary'].replace('P: ', 'Plan: ')\n",
    "        return example\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]  # 获取索引对应的数据项\n",
    "        ordered_item = {'id': item['id']}  # 创建一个新字典，并首先加入'id'\n",
    "        ordered_item.update({k: item[k] for k in item if k != 'id'})  # 添加其他字段，排除'id'\n",
    "        return ordered_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a743f4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f0e17587134d7e81d87d3961832525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1e83d801f04ed4adfb9ccea6b97662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759d048f8b2943d08a18f30a8584c7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39b80d727284d8fba7c0cbd16bd4463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1699f68f164663a312cfd961992684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f8f689e4ea4067a2c9b074e7c49b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 示例初始化\n",
    "train_data = MedicalDialogueDataset('train')\n",
    "valid_data = MedicalDialogueDataset('validation')\n",
    "test_data = MedicalDialogueDataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60c941c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 9250\n",
      "valid set size: 500\n",
      "test set size: 250\n",
      "{'id': '0', 'dialogue': \"Doctor: Hello, how can I help you today?\\nPatient: My son has been having some issues with speech and development. He's 13 years old now.\\nDoctor: I see. Can you tell me more about his symptoms? Does he have any issues with muscle tone or hypotonia?\\nPatient: No, he doesn't have hypotonia. But he has mild to moderate speech and developmental delay, and he's been diagnosed with attention deficit disorder.\\nDoctor: Thank you for sharing that information. We'll run some tests, including an MRI, to get a better understanding of your son's condition. \\n(After the tests)\\nDoctor: The MRI results are in, and I'm glad to say that there are no structural brain anomalies. However, I did notice some physical characteristics. Does your son have any facial features like retrognathia, mild hypertelorism, or a slightly elongated philtrum and thin upper lip?\\nPatient: Yes, he has all of those features. His hands are also broad and short. And his feet have mild syndactyly of the second and third toe, with a sandal gap in both feet.\\nDoctor: Thank you for confirming that. We also conducted Whole Exome Sequencing (WES) analyses, and we found a de novo frameshift variant in his genetic makeup. Specifically, it's Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)). This leads to a premature termination codon located more than 400 codons upstream of the canonical termination codon.\\nPatient: What does that mean for my son?\\nDoctor: This genetic variant may be contributing to your son's speech, developmental delay, and attention deficit disorder. It's important that we continue monitoring his progress and provide appropriate support for his development.\\nPatient: What should we do for follow-up?\\nDoctor: Regular visits with a speech and language therapist, an occupational therapist, and a psychologist can help address your son's developmental and attention deficit disorder needs. I will also recommend regular check-ups with me to monitor his growth and overall health.\\nPatient: Thank you, doctor. We will follow your recommendations and keep an eye on his progress.\", 'summary': \"Subjective: The patient's mother reports that her 13-year-old son has mild to moderate speech and developmental delays and has been diagnosed with attention deficit disorder. She denies any issues with muscle tone or hypotonia. The patient also exhibits certain physical characteristics, including retrognathia, mild hypertelorism, an elongated philtrum, thin upper lip, broad and short hands, mild syndactyly of the second and third toes, and a sandal gap in both feet.\\nObjective: An MRI of the brain showed no structural anomalies. Whole Exome Sequencing (WES) revealed a de novo frameshift variant Chr1(GRCh37):g.244217335del, NM_205768.2(ZBTB18):c.259del(p.(Leu87Cysfs*21)), indicating a premature termination codon located more than 400 codons upstream of the canonical termination codon.\\nAssessment: The primary diagnosis is a genetic disorder associated with the identified frameshift mutation, which likely contributes to the patient's speech and developmental delays and attention deficit disorder. The physical characteristics and genetic findings suggest a specific syndrome, which needs further correlation with clinical findings and genetic counseling.\\nPlan: The management plan includes regular follow-up visits with a speech and language therapist, an occupational therapist, and a psychologist to support the patient's developmental needs and address his attention deficit disorder. Regular medical check-ups will monitor his growth and overall health. Genetic counseling for the family is also recommended to discuss the implications of the genetic findings and potential familial inheritance.\"}\n"
     ]
    }
   ],
   "source": [
    "print(f'train set size: {len(train_data)}')\n",
    "print(f'valid set size: {len(valid_data)}')\n",
    "print(f'test set size: {len(test_data)}')\n",
    "print(next(iter(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae6e66ca-0c96-4e0f-8345-bbe46ef166fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gauravkoradiya/T5-Finetuned-Summarization-DialogueDataset\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bdca55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: tensor([[    0, 41152,    35,  ...,     1,     1,     1]])\n",
      "Tokens: ['<s>', 'Doctor', ':', 'ĠWhat', 'Ġbrings', 'Ġyou', 'Ġback', 'Ġinto', 'Ġthe', 'Ġclinic', 'Ġtoday', ',', 'Ġmiss', '?', 'ĠPatient', ':', 'ĠI', 'Ġcame', 'Ġin', 'Ġfor', 'Ġa', 'Ġrefill', 'Ġof', 'Ġmy', 'Ġblood', 'Ġpressure', 'Ġmedicine', '.', 'ĠDoctor', ':', 'ĠIt', 'Ġlooks', 'Ġlike', 'ĠDoctor', 'ĠKumar', 'Ġfollowed', 'Ġup', 'Ġwith', 'Ġyou', 'Ġlast', 'Ġtime', 'Ġregarding', 'Ġyour', 'Ġhypertension', ',', 'Ġoste', 'o', 'arth', 'ritis', ',', 'Ġoste', 'op', 'or', 'osis', ',', 'Ġhyp', 'othy', 'roid', 'ism', ',', 'Ġallergic', 'Ġrh', 'in', 'itis', 'Ġand', 'Ġkidney', 'Ġstones', '.', 'Ġ', 'ĠHave', 'Ġyou', 'Ġnoticed', 'Ġany', 'Ġchanges', 'Ġor', 'Ġdo', 'Ġyou', 'Ġhave', 'Ġany', 'Ġconcerns', 'Ġregarding', 'Ġthese', 'Ġissues', '?', 'ĠPatient', ':', 'ĠNo', '.', 'ĠDoctor', ':', 'ĠHave', 'Ġyou', 'Ġhad', 'Ġany', 'Ġfever', 'Ġor', 'Ġch', 'ills', ',', 'Ġcough', ',', 'Ġcongestion', ',', 'Ġnausea', ',', 'Ġvomiting', ',', 'Ġchest', 'Ġpain', ',', 'Ġchest', 'Ġpressure', '?', 'Pat', 'ient', ':', 'ĠNo', '.', 'ĠDoctor', ':', 'ĠGreat', '.', 'ĠAlso', ',', 'Ġfor', 'Ġour', 'Ġrecords', ',', 'Ġhow', 'Ġold', 'Ġare', 'Ġyou', 'Ġand', 'Ġwhat', 'Ġrace', 'Ġdo', 'Ġyou', 'Ġidentify', 'Ġyourself', 'Ġas', '?', 'Pat', 'ient', ':', 'ĠI', 'Ġam', 'Ġseventy', 'Ġsix', 'Ġyears', 'Ġold', 'Ġand', 'Ġidentify', 'Ġas', 'Ġa', 'Ġwhite', 'Ġfemale', '.', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "dialogue = \"Doctor: What brings you back into the clinic today, miss? Patient: I came in for a refill of my blood pressure medicine. Doctor: It looks like Doctor Kumar followed up with you last time regarding your hypertension, osteoarthritis, osteoporosis, hypothyroidism, allergic rhinitis and kidney stones.  Have you noticed any changes or do you have any concerns regarding these issues? Patient: No. Doctor: Have you had any fever or chills, cough, congestion, nausea, vomiting, chest pain, chest pressure?Patient: No. Doctor: Great. Also, for our records, how old are you and what race do you identify yourself as?Patient: I am seventy six years old and identify as a white female.\"\n",
    "inputs = tokenizer(dialogue, return_tensors=\"pt\", max_length=1024, truncation=True, padding=\"max_length\")\n",
    "summary = \"The patient is a 76-year-old white female who presents to the clinic today originally for hypertension and a med check.  She has a history of hypertension, osteoarthritis, osteoporosis, hypothyroidism, allergic rhinitis and kidney stones.  Since her last visit she has been followed by Dr. Kumar.  Those issues are stable.  She has had no fever or chills, cough, congestion, nausea, vomiting, chest pain, chest pressure.\"\n",
    "# 对目标摘要进行编码\n",
    "targets = tokenizer(summary, return_tensors=\"pt\", max_length=1024, truncation=True, padding=\"max_length\")\n",
    "# 打印输入的令牌ID和对应的文本表示\n",
    "print('Token IDs:', inputs['input_ids'])\n",
    "print('Tokens:', tokenizer.convert_ids_to_tokens(inputs['input_ids'][0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f418b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d1a2e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lixuemeng/anaconda3/envs/transformers/lib/python3.9/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSeq2SeqLM, AdamW\n",
    "\n",
    "max_input_length = 512\n",
    "max_target_length = 64\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"gauravkoradiya/T5-Finetuned-Summarization-DialogueDataset\").to(device).half()\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "523d179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collote_fn(batch_samples):\n",
    "    batch_inputs, batch_targets = [], []\n",
    "    for sample in batch_samples:\n",
    "        batch_inputs.append(sample['dialogue'])\n",
    "        batch_targets.append(sample['summary'])\n",
    "    batch_data = tokenizer(\n",
    "        batch_inputs, \n",
    "        padding=True, \n",
    "        max_length=max_input_length,\n",
    "        truncation=True, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            batch_targets, \n",
    "            padding=True, \n",
    "            max_length=max_target_length,\n",
    "            truncation=True, \n",
    "            return_tensors=\"pt\"\n",
    "        )[\"input_ids\"]\n",
    "        batch_data['decoder_input_ids'] = model.prepare_decoder_input_ids_from_labels(labels)\n",
    "        end_token_index = torch.where(labels == tokenizer.eos_token_id)[1]\n",
    "        for idx, end_idx in enumerate(end_token_index):\n",
    "            labels[idx][end_idx+1:] = -100\n",
    "        batch_data['labels'] = labels\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a4c2710",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=4, shuffle=True, collate_fn=collote_fn)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=4, shuffle=False, collate_fn=collote_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6300f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'decoder_input_ids', 'labels'])\n",
      "batch shape: {'input_ids': torch.Size([4, 512]), 'attention_mask': torch.Size([4, 512]), 'decoder_input_ids': torch.Size([4, 64]), 'labels': torch.Size([4, 64])}\n",
      "{'input_ids': tensor([[    0, 41152,    35,  ...,     1,     1,     1],\n",
      "        [    0, 41152,    35,  ...,    38,   192,     2],\n",
      "        [    0, 41152,    35,  ...,  1302,    14,     2],\n",
      "        [    0, 41152,    35,  ...,   110,   618,     2]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'decoder_input_ids': tensor([[    2,     0, 47159,  2088,    35,    20,  3186,   690,  2157,    22,\n",
      "           102,   828,   160,   113,   187,   618, 23655,   183,   290,   511,\n",
      "            10,   235,  2853, 22362, 36291,     8, 18422,  1988,  6204, 23496,\n",
      "         37908,  2982, 22580,    13, 10665,  1668,     4,    20,  3186,    34,\n",
      "            57,  7242,  5718,  2292,  1182,   783,  1057, 18620,     4, 50118,\n",
      "         46674,  2088,    35,    20,  3186,    18,   230,    12,   241, 12228,\n",
      "          8276,    36,  9822,   510],\n",
      "        [    2,     0, 47159,  2088,    35,    20,  3186,    16,    10,  3550,\n",
      "            12,   180,    12,   279,   693,    19,    10,   750,     9, 33076,\n",
      "          5183,  6436,  2430,  6181,  1668,     8, 10665, 33076,  9354,     6,\n",
      "         10864,    19, 35583,  2489,   991,  1517,  2553, 20394,    81,     5,\n",
      "           375,   411,   377,     4,   264,   690,  1233, 13250,   528,     7,\n",
      "         33169,    62,  2219,  5962, 38762,     9,  1925,  1230,     4,  1405,\n",
      "          1131,   750,  1171,    10],\n",
      "        [    2,     0, 47159,  2088,    35, 27690,   690,  7242, 33073,  4406,\n",
      "          2400,    15,     5,   314,   526,     9,     5,   471,     8,   652,\n",
      "            13,    10,    76,     6, 21319,    81,     5,   375,   379,   360,\n",
      "             4,    20,  2400, 11493,  1230,     6,  9735,   155,    12,   306,\n",
      "           722,     6,     8, 18420, 10687,    71, 33842,     4,    20,  2400,\n",
      "            16, 35668,     7,     5,   314, 15401,     6, 10295,  9927,     6,\n",
      "             8,  2295,   443,     4],\n",
      "        [    2,     0, 47159,  2088,    35,    20,  3186,     6,  1433,  6443,\n",
      "            19, 29851, 21431, 41281, 13310,     6, 12796,    10,   230,   246,\n",
      "            12,   347,   401,   784, 13941, 36291,     8,  2982,  1755,  3894,\n",
      "         13604,     4,  1869,  8428, 10481,     6,     5,  3186,  2984,    92,\n",
      "         27548,  5298,     8,  2284, 29184,  8645,  5347,   354,     4, 12845,\n",
      "         18838,  6209,    11,   430,  2452,   969, 29851, 26640,   528,     7,\n",
      "          2292,  2832,  4360, 13310]]), 'labels': tensor([[    0, 47159,  2088,    35,    20,  3186,   690,  2157,    22,   102,\n",
      "           828,   160,   113,   187,   618, 23655,   183,   290,   511,    10,\n",
      "           235,  2853, 22362, 36291,     8, 18422,  1988,  6204, 23496, 37908,\n",
      "          2982, 22580,    13, 10665,  1668,     4,    20,  3186,    34,    57,\n",
      "          7242,  5718,  2292,  1182,   783,  1057, 18620,     4, 50118, 46674,\n",
      "          2088,    35,    20,  3186,    18,   230,    12,   241, 12228,  8276,\n",
      "            36,  9822,   510,     2],\n",
      "        [    0, 47159,  2088,    35,    20,  3186,    16,    10,  3550,    12,\n",
      "           180,    12,   279,   693,    19,    10,   750,     9, 33076,  5183,\n",
      "          6436,  2430,  6181,  1668,     8, 10665, 33076,  9354,     6, 10864,\n",
      "            19, 35583,  2489,   991,  1517,  2553, 20394,    81,     5,   375,\n",
      "           411,   377,     4,   264,   690,  1233, 13250,   528,     7, 33169,\n",
      "            62,  2219,  5962, 38762,     9,  1925,  1230,     4,  1405,  1131,\n",
      "           750,  1171,    10,     2],\n",
      "        [    0, 47159,  2088,    35, 27690,   690,  7242, 33073,  4406,  2400,\n",
      "            15,     5,   314,   526,     9,     5,   471,     8,   652,    13,\n",
      "            10,    76,     6, 21319,    81,     5,   375,   379,   360,     4,\n",
      "            20,  2400, 11493,  1230,     6,  9735,   155,    12,   306,   722,\n",
      "             6,     8, 18420, 10687,    71, 33842,     4,    20,  2400,    16,\n",
      "         35668,     7,     5,   314, 15401,     6, 10295,  9927,     6,     8,\n",
      "          2295,   443,     4,     2],\n",
      "        [    0, 47159,  2088,    35,    20,  3186,     6,  1433,  6443,    19,\n",
      "         29851, 21431, 41281, 13310,     6, 12796,    10,   230,   246,    12,\n",
      "           347,   401,   784, 13941, 36291,     8,  2982,  1755,  3894, 13604,\n",
      "             4,  1869,  8428, 10481,     6,     5,  3186,  2984,    92, 27548,\n",
      "          5298,     8,  2284, 29184,  8645,  5347,   354,     4, 12845, 18838,\n",
      "          6209,    11,   430,  2452,   969, 29851, 26640,   528,     7,  2292,\n",
      "          2832,  4360, 13310,     2]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lixuemeng/anaconda3/envs/transformers/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "print(batch.keys())\n",
    "print('batch shape:', {k: v.shape for k, v in batch.items()})\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6958203-8697-4929-b4dc-dc242e6a4ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_loop(dataloader, model, optimizer, lr_scheduler, epoch, total_loss):\n",
    "    progress_bar = tqdm(range(len(dataloader)))\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_batch_num = (epoch-1) * len(dataloader)\n",
    "    \n",
    "    model.train()\n",
    "    for batch, batch_data in enumerate(dataloader, start=1):\n",
    "        batch_data = batch_data.to(device)\n",
    "        outputs = model(**batch_data)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_description(f'loss: {total_loss/(finish_batch_num + batch):>7f}')\n",
    "        progress_bar.update(1)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "def test_loop(dataloader, model):\n",
    "\n",
    "    preds, labels = [], []\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_data in tqdm(dataloader):\n",
    "        # batch_data = batch_data.to(device)\n",
    "        batch_data = {k: v.to(device) for k, v in batch_data.items()}\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model.generate(\n",
    "                batch_data[\"input_ids\"],\n",
    "                attention_mask=batch_data[\"attention_mask\"],\n",
    "                max_length=max_target_length,\n",
    "                num_beams=4,\n",
    "                no_repeat_ngram_size=2,\n",
    "            ).cpu().numpy()\n",
    "        if isinstance(generated_tokens, tuple):\n",
    "            generated_tokens = generated_tokens[0]\n",
    "        label_tokens = batch_data[\"labels\"].cpu().numpy()\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        label_tokens = np.where(label_tokens != -100, label_tokens, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
    "\n",
    "        preds += [' '.join(pred.strip()) for pred in decoded_preds]\n",
    "        labels += [' '.join(label.strip()) for label in decoded_labels]\n",
    "    scores = rouge.get_scores(hyps=preds, refs=labels, avg=True)\n",
    "    result = {key: value['f'] * 100 for key, value in scores.items()}\n",
    "    result['avg'] = np.mean(list(result.values()))\n",
    "    print(f\"Rouge1: {result['rouge-1']:>0.2f} Rouge2: {result['rouge-2']:>0.2f} RougeL: {result['rouge-l']:>0.2f}\\n\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d0eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "learning_rate = 2e-5\n",
    "epoch_num = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=epoch_num*len(train_dataloader),\n",
    ")\n",
    "\n",
    "total_loss = 0.\n",
    "best_avg_rouge = 0.\n",
    "for t in range(epoch_num):\n",
    "    print(f\"Epoch {t+1}/{epoch_num}\\n-------------------------------\")\n",
    "    total_loss = train_loop(train_dataloader, model, optimizer, lr_scheduler, t+1, total_loss)\n",
    "    valid_rouge = test_loop(valid_dataloader, model)\n",
    "    print(valid_rouge)\n",
    "    rouge_avg = valid_rouge['avg']\n",
    "    if rouge_avg > best_avg_rouge:\n",
    "        best_avg_rouge = rouge_avg\n",
    "        print('saving new weights...\\n')\n",
    "        torch.save(model.state_dict(), f'epoch_{t+1}_valid_rouge_{rouge_avg:0.4f}_model_weights.bin')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9365acfc",
   "metadata": {},
   "source": [
    "## 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ec4e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('MTS-Dialog-Combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "442947b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bc49503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'dialogue', 'summary'],\n",
       "        num_rows: 1170\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'dialogue', 'summary'],\n",
       "        num_rows: 131\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = datasets.train_test_split(test_size= 0.1)\n",
    "datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f050966",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m----> 2\u001b[0m summarizes \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSummarization\u001b[39m\u001b[38;5;124m\"\u001b[39m, model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m, tokenizer \u001b[38;5;241m=\u001b[39m tokenizer)\n\u001b[1;32m      3\u001b[0m conversation \u001b[38;5;241m=\u001b[39m datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdialogue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m predice \u001b[38;5;241m=\u001b[39m summarizes(conversation)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizes = pipeline(\"Summarization\", model = model, tokenizer = tokenizer)\n",
    "conversation = datasets['train'][0][\"dialogue\"]\n",
    "predict = summarizes(conversation)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = datasets[\"train\"][0][\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef6028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "rouge.get_score(predict[0][\"summary_text\"], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41aeacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "for dataset in datasets [\"test \"]:\n",
    "    predict = summarizer(datasets[\"dialogue\"])\n",
    "    label = dataset[\"summary\"]\n",
    "    score = rouge.get_score(predict[0][\"summary_text\"], label)[0][\"rougel_l\"][\"f\"]\n",
    "    score_list.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc3bbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.mean(score_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
